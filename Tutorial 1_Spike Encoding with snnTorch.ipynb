{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RBNKFLJIobYt"
      },
      "source": [
        "[<img src='https://github.com/jeshraghian/snntorch/blob/master/docs/_static/img/snntorch_alpha_w.png?raw=true' width=\"400\">](https://github.com/jeshraghian/snntorch/)\n",
        "\n",
        "# Tutorial 1 - Spike Encoding\n",
        "## By Jason K. Eshraghian (www.ncg.ucsc.edu)\n",
        "## 偏白话文翻译： manesec\n",
        "\n",
        "<a href=\"https://colab.research.google.com/github/jeshraghian/snntorch/blob/master/examples/tutorial_1_spikegen.ipynb\">\n",
        "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
        "</a>\n",
        "\n",
        "[<img src='https://github.com/jeshraghian/snntorch/blob/master/docs/_static/img/GitHub-Mark-Light-120px-plus.png?raw=true' width=\"28\">](https://github.com/jeshraghian/snntorch/) [<img src='https://github.com/jeshraghian/snntorch/blob/master/docs/_static/img/GitHub_Logo_White.png?raw=true' width=\"80\">](https://github.com/jeshraghian/snntorch/)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4blpfg4y44uO"
      },
      "source": [
        "snnTorch 教程系列基于以下论文。如果您发现这些资源或代码对您有帮助，请考虑引用以下来源：\n",
        "\n",
        "> <cite> [Jason K. Eshraghian, Max Ward, Emre Neftci, Xinxin Wang, Gregor Lenz, Girish Dwivedi, Mohammed Bennamoun, Doo Seok Jeong, and Wei D. Lu. \"Training Spiking Neural Networks Using Lessons From Deep Learning\". arXiv preprint arXiv:2109.12894, September 2021.](https://arxiv.org/abs/2109.12894) </cite>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lnF_PEo5obYv",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "在本教程中，您将学习如何使用 snnTorch：\n",
        "* 将数据集转换为尖峰数据集、\n",
        "* 如何将其可视化、\n",
        "* 以及如何生成随机尖峰列车 (spike trains)。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d7qhH_lt8_mn"
      },
      "source": [
        "# 介绍\n",
        "\n",
        "更好的理解：“尖峰” 可以理解成是生物电，在你被针扎的时候组织会放出很高的生物电，然后经过神经，最后大脑开始有感知。这个生物电就如下面所提到的“尖峰”。 \n",
        "\n",
        "当视网膜将光子转化为尖峰时，我们看到的是光。当挥发的分子转化为尖峰时，我们能闻到味道。当神经将触觉压力转化为尖峰时，我们会有感觉。\"尖峰\" 就像是大脑里的货币。\n",
        "\n",
        "如果我们的最终目标是构建尖峰神经网络（SNN），那么在输入端使用尖峰也是合理的。虽然使用非尖峰输入也很常见（如教程 3 所示），但数据编码的魅力部分来自于三个S：尖峰（spikes）、稀疏性（sparsity）和静态抑制（static suppression）。\n",
        "\n",
        "\n",
        "1.   **尖峰**： (a-b) 生物神经元通过尖峰进行处理和交流，尖峰是振幅约为 100 mV 的电脉冲。(c) 许多神经元计算模型将这种电压脉冲简化成离散的单比特事件：\"1 \"或 \"0\"。这在硬件中表示比高精度电压值要简单得多。\n",
        "\n",
        "2.   **稀疏性**： (c) 神经元大部分时间处于休息状态，在任何给定时间将大多数都是输入 “零”。  稀疏向量 / 张量（带有大量零）不仅存储成本低廉，而且我们只需要将稀疏激活与突触权重相乘。  如果大多数值都乘以 “0”，那么就不需要从内存中读取其他网络。这意味着神经形态的硬件可以非常高效。\n",
        "\n",
        "\n",
        "3.   **静态抑制（又称事件驱动处理）**： (d-e）外围感知层只有在有新信息需要处理时才会处理信息。(e)中的每个像素都会对光亮度而做出*变化*，因此大部分图像都被遮挡住了。传统的信号处理要求输入所有通道/像素都会进行全局采样/快门速度，这就降低了感测的频率。现在，事件驱动处理是只输入变化的数据，阻止输入原本不变的数据，不仅有助于提高效率，而且通常还能大大加快处理速度。\n",
        "\n",
        "\n",
        "<center>\n",
        "<img src='https://github.com/jeshraghian/snntorch/blob/master/docs/_static/img/examples/tutorial1/3s.png?raw=true' width=\"600\">\n",
        "</center>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lGNOnFM4DzHY"
      },
      "source": [
        "在本教程中，我们假设我们有一些非尖峰输入数据（即 MNIST 数据集），并且我们希望使用几种不同的技术将其编码为尖峰。那么让我们开始吧！"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GAbXmmVN50Pl"
      },
      "source": [
        "安装 snnTorch 的最新 PyPi 发行版："
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jxLoYgkhobYw",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "!pip install snntorch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k6E7VH5kbTmA"
      },
      "source": [
        "## 1. 设置 MNIST 数据集"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Suffg8_ZobYw",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "### 1.1. 导入包并设置环境"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cR9okh0jobYx",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "import snntorch as snn\n",
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e4LPD0WCobYx",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "# 训练参数\n",
        "batch_size=128\n",
        "data_path='/data/mnist'\n",
        "num_classes = 10  # MNIST 有 10 个输出类别\n",
        "\n",
        "# Torch 变量\n",
        "dtype = torch.float"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x5X2a5a9obYy"
      },
      "source": [
        "### 1.2 下载数据集"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OlbY8Rm9obYy",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "from torchvision import datasets, transforms\n",
        "\n",
        "# 定义一个 transform\n",
        "transform = transforms.Compose([\n",
        "            transforms.Resize((28,28)),\n",
        "            transforms.Grayscale(),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize((0,), (1,))])\n",
        "\n",
        "mnist_train = datasets.MNIST(data_path, train=True, download=True, transform=transform)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6ZyzEp9YHgPb"
      },
      "source": [
        "如果上面的代码块抛出错误，例如 MNIST 服务器已关闭，可以取消注释以下代码。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZpGLLVqeHgwy"
      },
      "outputs": [],
      "source": [
        "# # temporary dataloader if MNIST service is unavailable\n",
        "# !wget www.di.ens.fr/~lelarge/MNIST.tar.gz\n",
        "# !tar -zxvf MNIST.tar.gz\n",
        "\n",
        "# mnist_train = datasets.MNIST(root = './', train=True, download=True, transform=transform)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T5wXl2bVobYz",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "在我们真正开始训练网络之前，我们不需要大型数据集。\n",
        "`snntorch.utils` 里面包含一个减少数据集的函数，应用 `data_subset` 以按 `subset` 中定义的因子来减少数据集。 \n",
        "\n",
        "例如，对于 `subset=10`，60,000 个训练集将减少到 6,000 个。\n",
        "\n",
        "注：60,000 / (subset) = 6,000"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5FPsPU46obYz",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "from snntorch import utils\n",
        "\n",
        "subset = 10\n",
        "mnist_train = utils.data_subset(mnist_train, subset)\n",
        "print(f\"The size of mnist_train is {len(mnist_train)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9CedMagsobY0",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "### 1.3 创建数据加载器\n",
        "上面创建的 Dataset 对象将数据加载到内存中，DataLoader 将批量提供它。 PyTorch 中的 DataLoader 是将数据传递到网络的便捷接口。  它们返回一个迭代器，该迭代器被划分为大小为 `batch_size` 的小批量。\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TrJLlWj2obY0",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "train_loader = DataLoader(mnist_train, batch_size=batch_size, shuffle=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mwSdczxKobY0",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "## 2. 尖峰编码\n",
        "\n",
        "尖峰神经网络 (SNN) 旨在利用时变数据。然而，MNIST 并不是一个随时间变化的数据集。\n",
        "将 MNIST 与 SNN 结合使用有两种选择：\n",
        "\n",
        "1. 在每个时间步重复将相同的训练样本 $\\mathbf{X}\\in\\mathbb{R}^{m\\times n}$ 传递到网络。 这就像将 MNIST 转换为静态、不变的视频。 $\\mathbf{X}$ 的每个元素都可以采用 0 到 1 之间归一化的高精度值：$X_{ij}\\in [0, 1]$。\n",
        "\n",
        "<center>\n",
        "<img src='https://github.com/jeshraghian/snntorch/blob/master/docs/_static/img/examples/tutorial1/1_2_1_static.png?raw=true' width=\"700\">\n",
        "</center>\n",
        "\n",
        "\n",
        "2. 将输入转换为序列长度为`num_steps`的尖峰序列，其中每个特征/像素均采用离散值 $X_{i,j} \\in \\{0, 1\\}$。\n",
        "在这种情况下，MNIST 被转换为随时间变化的尖峰序列，其特征在于与原始图像的关系。\n",
        "\n",
        "<center>\n",
        "<img src='https://github.com/jeshraghian/snntorch/blob/master/docs/_static/img/examples/tutorial1/1_2_2_spikeinput.png?raw=true' width=\"700\">\n",
        "</center>\n",
        "\n",
        "第一种方法非常简单，但是没有充分利用 SNN 的时间动态。 因此，让我们更详细地考虑第二种中的数据到尖峰的转换（编码）。\n",
        "\n",
        "模块`snntorch.spikegen`（即尖峰生成器）包含一系列可简化数据到尖峰转换的函数。 目前，`snntorch` 中的尖峰编码可使用三个选项：\n",
        "\n",
        "1. *速率编码* : [`spikegen.rate`](https://snntorch.readthedocs.io/en/latest/snntorch.spikegen.html#snntorch.spikegen.rate)\n",
        "2. *速率编码* : [`spikegen.latency`](https://snntorch.readthedocs.io/en/latest/snntorch.spikegen.html#snntorch.spikegen.latency)\n",
        "3. *Delta 调制* : [`spikegen.delta`](https://snntorch.readthedocs.io/en/latest/snntorch.spikegen.html#snntorch.spikegen.delta)\n",
        "\n",
        "他们有什么区别？\n",
        "\n",
        "1. *速率编码* 使用输入特征来确定尖峰 **频率**\n",
        "2. *延迟编码*  使用输入特征来确定尖峰 **时序**\n",
        "3. *Delta 调制* 使用输入特征的时间 **变化** 来生成尖峰\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3D5HSoY4bQDm"
      },
      "source": [
        "### 2.1 MNIST 的速率编码\n",
        "\n",
        "将输入数据转换为速率编码的一个示例如下：\n",
        "\n",
        "每个归一化输入特征 $X_{ij}$ 用作在任何给定时间步发生事件（尖峰）的概率，返回速率编码值 $R_{ij}$。  这可以视为伯努利试验：$R_{ij}\\sim B (n,p)$，其中试验次数为 $n=1$，成功（尖峰）的概率为 $p=X_{ ij}$。  明确地，峰值发生的概率为：\n",
        "\n",
        "$${\\rm P}(R_{ij}=1) = X_{ij} = 1 - {\\rm P}(R_{ij} = 0)$$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DxorUvomL1ei"
      },
      "outputs": [],
      "source": [
        "# Temporal Dynamics\n",
        "num_steps = 10\n",
        "\n",
        "# 生成一个矩阵向量是0.5，根据0.5的概率为矩阵里面的每个数生成0或者1。\n",
        "raw_vector = torch.ones(num_steps)*0.5\n",
        "\n",
        "# 从伯努利分布提取二进制随机数（0 或 1）,输入张量为二进制随机数的概率。\n",
        "# 因此，输入中的所有值都必须在以下范围内 (0,1)。\n",
        "# 根据 输入的概率 随机输出 0或者1\n",
        "rate_coded_vector = torch.bernoulli(raw_vector)\n",
        "\n",
        "print(f\"Converted vector: {rate_coded_vector}\")\n",
        "print(f\"The output is spiking {rate_coded_vector.sum()*100/len(rate_coded_vector):.2f}% of the time.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l0E8Z8mSNflV"
      },
      "source": [
        "现在再试一次，但增加 `raw_vector` 的长度："
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y6uUgpktNjBg"
      },
      "outputs": [],
      "source": [
        "num_steps = 100\n",
        "\n",
        "# create vector filled with 0.5\n",
        "raw_vector = torch.ones(num_steps)*0.5\n",
        "\n",
        "# pass each sample through a Bernoulli trial\n",
        "rate_coded_vector = torch.bernoulli(raw_vector)\n",
        "print(f\"The output is spiking {rate_coded_vector.sum()*100/len(rate_coded_vector):.2f}% of the time.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zoLxfVoINzdH"
      },
      "source": [
        "可以看到随着大小 `num_steps`$\\rightarrow\\infty$ 的增加，尖峰的比例会越来越逐渐接近原始值。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eYKsWmoGLz6S"
      },
      "source": [
        "对于 MNIST 图像，尖峰概率与像素值相对应。白色像素对应 100%的尖峰概率，而黑色像素永远不会产生尖峰。上面三个S的编码如下，请看下面的 \"速率编码 \"一栏，了解更多直观信息。\n",
        "\n",
        "\n",
        "<center>\n",
        "<img src='https://github.com/jeshraghian/snntorch/blob/master/docs/_static/img/examples/tutorial1/1_2_3_spikeconv.png?raw=true' width=\"1000\">\n",
        "</center>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k8_Lzm6FOcm0"
      },
      "source": [
        "类似地，`spikegen.rate`也可用于生成速率编码的数据样本。由于 MNIST 的每个样本只是一个图像，我们可以使用 `num_steps` 跨时间重复。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nz70JGXqobY1",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "from snntorch import spikegen\n",
        "\n",
        "# 通过迷你批次迭代\n",
        "data = iter(train_loader)\n",
        "data_it, targets_it = next(data)\n",
        "\n",
        "# 产生尖峰数据\n",
        "spike_data = spikegen.rate(data_it, num_steps=num_steps)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q0hATEwKobY1",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "\n",
        "如果输入值超出 $[0,1]$，则不再代表概率。这种情况会被自动剪切，以确保特征代表一个概率。\n",
        "\n",
        "输入数据的结构是 ``[num_steps x batch_size x input dimensions]``："
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ebdP5kFKobY2",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "print(spike_data.size())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cnas5Q89l_10"
      },
      "source": [
        "### 2.2 可视化"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oVFuIXxMobY2",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "#### 2.2.1 动画\n",
        "snnTorch 包含一个模块 [`snntorch.spikeplot`](https://snntorch.readthedocs.io/en/latest/snntorch.spikeplot.html)，可简化尖峰神经元的可视化、绘图和动画过程。\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4TYFlc4_ZK-u"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import snntorch.spikeplot as splt\n",
        "from IPython.display import HTML"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fwWROIkdobY3",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "要绘制一个数据样本，请从 `spike_data` 的批次 (B) 维度 ``[T x B x 1 x 28 x 28]`` 中索引到一个样本："
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZZxTqqOlobY3",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "spike_data_sample = spike_data[:, 0, 0]\n",
        "print(spike_data_sample.size())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lJJyPUiuQ61x"
      },
      "source": [
        "`spikeplot.animator` 使 2-D 数据的动画制作变得超级简单。\n",
        "\n",
        "注意：如果您在本地运行，可能需要安装 ffmpeg：例如，`pip install ffmpeg` 或在 Conda 环境中，`conda install -c conda-forge ffmpeg`。\n",
        "\n",
        "如果找不到 ffmpeg，请取消下面一行的注释并修改 ffmpeg.exe 的路径。\n",
        "\n",
        "ffmpeg下载：https://www.gyan.dev/ffmpeg/builds/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4QVyvj9PobY3",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "fig, ax = plt.subplots()\n",
        "anim = splt.animator(spike_data_sample, fig, ax)\n",
        "plt.rcParams['animation.ffmpeg_path'] = 'D:\\\\GoodApp\\\\ffmpeg\\\\bin\\\\ffmpeg.exe'\n",
        "\n",
        "HTML(anim.to_html5_video())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ko8KJBCNobY4",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "# 如果您有感而发，可以保存动画：.gif、.mp4 等。\n",
        "anim.save(\"spike_mnist_test.mp4\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gu1_f0XZobY4",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "目标标签索引如下: "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7Yb76uofobY4",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "print(f\"The corresponding target is: {targets_it[0]}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YTRqW-wtobY5",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "MNIST 以灰度图像为特征，白色文本保证了每个时间步的尖峰频率为 100%。因此，我们再来一次，但要降低尖峰频率。这可以通过设置参数 `gain`来实现。在这里，我们将尖峰频率降低到 25%。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ymxnM4CaobY5",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "# 将尖峰频率降低到 25%\n",
        "spike_data = spikegen.rate(data_it, num_steps=num_steps, gain=0.25)\n",
        "\n",
        "# 输出图像\n",
        "spike_data_sample2 = spike_data[:, 0, 0]\n",
        "fig, ax = plt.subplots()\n",
        "anim = splt.animator(spike_data_sample2, fig, ax)\n",
        "HTML(anim.to_html5_video())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dicJdyG2obY5",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "# Uncomment for optional save\n",
        "# anim.save(\"spike_mnist_test2.mp4\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JgPZBNIaobY5"
      },
      "source": [
        "现在，将尖峰图像按时间平均，重建输入图像。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e4ikMCQLobY6",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "plt.figure(facecolor=\"w\")\n",
        "plt.subplot(1,2,1)\n",
        "plt.imshow(spike_data_sample.mean(axis=0).reshape((28,-1)).cpu(), cmap='binary')\n",
        "plt.axis('off')\n",
        "plt.title('Gain = 1')\n",
        "\n",
        "plt.subplot(1,2,2)\n",
        "plt.imshow(spike_data_sample2.mean(axis=0).reshape((28,-1)).cpu(), cmap='binary')\n",
        "plt.axis('off')\n",
        "plt.title('Gain = 0.25')\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6bbbI1o2obY7",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "`gain=0.25` 的情况比 `gain=1` 的情况轻，因为尖峰概率降低了4倍。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WpfpKe3zobY8",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "#### 2.2.2 栅格图\n",
        "或者，我们可以生成输入样本的栅格图。 这需要将样本重塑为二维张量，其中“时间”是第一个维度。 将此示例传递到函数`spikeplot.raster`。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KCpsLPySobY8",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "# Reshape\n",
        "spike_data_sample2 = spike_data_sample2.reshape((num_steps, -1))\n",
        "\n",
        "# raster plot\n",
        "fig = plt.figure(facecolor=\"w\", figsize=(10, 5))\n",
        "ax = fig.add_subplot(111)\n",
        "splt.raster(spike_data_sample2, ax, s=1.5, c=\"black\")\n",
        "\n",
        "plt.title(\"Input Layer\")\n",
        "plt.xlabel(\"Time step\")\n",
        "plt.ylabel(\"Neuron Number\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WvhIdrAZobY9",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "以下代码片段展示了如何索引单个神经元。\n",
        "根据输入数据，您可能需要尝试在找到一个 0 到 784 之间的几个不同的神经元之前尖峰。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R3kY3uoOobY9",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "idx = 210  # index into 210th neuron\n",
        "\n",
        "fig = plt.figure(facecolor=\"w\", figsize=(8, 1))\n",
        "ax = fig.add_subplot(111)\n",
        "\n",
        "splt.raster(spike_data_sample.reshape(num_steps, -1)[:, idx].unsqueeze(1), ax, s=100, c=\"black\", marker=\"|\")\n",
        "\n",
        "plt.title(\"Input Neuron\")\n",
        "plt.xlabel(\"Time step\")\n",
        "plt.yticks([])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1lxp91nlobY-",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "#### 2.2.3 速率编码总结\n",
        "速率编码的想法实际上还是有争议的，尽管我们相当确信速率编码确实发生在我们的感知外围，但我们并不确信大脑皮层会将信息全面编码为尖峰速率。几个令人信服的理由包括：\n",
        "\n",
        "* **功耗：** 自然优化效率。 完成任何任务都需要多个尖峰，而每个尖峰都会消耗能量，事实上，[Olshausen 和 Field 在“V1 的其他 85% 在做什么？”中的工作](http://www.rctn.org/bruno/papers/V1-chapter.pdf) 表明，速率编码最多只能解释初级视觉皮层 (V1) 中 15% 神经元的活动。它不可能是大脑内唯一的机制，因为大脑资源有限，而且效率很高。\n",
        "\n",
        "\n",
        "* **反应响应时间：** 我们知道人类的反应时间大约在 250 毫秒左右。 如果人脑神经元的平均放电频率约为 10Hz，那么我们在反应时间尺度内只能处理大约 2 个尖峰。\n",
        "\n",
        "那么，如果速率代码对于功率效率或延迟而言不是最佳的，那么为什么我们还要使用速率代码呢？ 即使我们的大脑不按速率处理数据，我们也相当确信我们的生物传感器会这样做。功率/延迟方面的劣势被巨大的噪声鲁棒性所部分抵消：即使有些尖峰无法产生也没关系，因为还会有更多的尖峰出现。\n",
        "\n",
        "此外，您可能听说过[赫布咒语“神经元一起放电，连接在一起”](https://doi.org/10.2307/1418888)。 如果有大量的尖峰，这可能表明有大量的学习。 在某些情况下，训练 SNN 被证明具有挑战性，通过速率代码鼓励更多尖峰是一种可能的解决方案。\n",
        "\n",
        "速率编码几乎肯定与大脑中的其他编码方案结合使用。 我们将在以下部分中考虑这些其他编码机制。\n",
        "这涵盖了`spikegen.rate`函数。 更多信息[可以在此处的文档中找到](https://snntorch.readthedocs.io/en/latest/snntorch.spikegen.html)。\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "enzqRvuNobY-",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "### 2.3 MNIST 的延迟编码\n",
        "时间代码捕获有关神经元精确放电时间的信息； 单个尖峰比依赖于发射频率的速率代码具有更多的意义。 虽然这对噪声更加敏感，但它也可以将运行 SNN 算法的硬件消耗的功耗降低几个数量级。\n",
        "\n",
        "`spikegen.latency` 是一个函数，允许每个输入在全时间扫描期间最多触发 **一次**。\n",
        "接近“1”的功能将更早触发，接近“0”的功能将稍后触发。 也就是说，在我们的 MNIST 案例中，亮像素会更早触发，暗像素会稍后触发。\n",
        "\n",
        "以下使用块驱动来解释工作原理。 如果您忘记了 电路理论/数学理论，那么不用担心！ 只要记住：**大**输入意味着**快**峰值； **小**输入意味着**迟**尖峰。\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d5yZdcX4So-W"
      },
      "source": [
        "---\n",
        "**可选：延迟代码机制的推导**\n",
        "\n",
        "默认情况下，通过将输入特征视为 RC 电路中的电流注入 $I_{in}$ 来计算尖峰时序。 该电流将电荷转移到电容器上，从而增加 $V(t)$。 我们假设有一个触发电压 $V_{thr}$，一旦达到该电压，就会产生一个尖峰。 那么问题就变成了：*对于给定的输入电流（以及等效的输入特征），生成尖峰需要多长时间？*\n",
        "\n",
        "从基尔霍夫电流定律 $I_{in} = I_R + I_C$ 开始，其余的推导使我们得出时间和输入之间的对数关系。\n",
        "\n",
        "<center>\n",
        "<img src='https://github.com/jeshraghian/snntorch/blob/master/docs/_static/img/examples/tutorial1/1_2_4_latencyrc.png?raw=true' width=\"600\">\n",
        "</center>\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DqJlK7AhjGHw"
      },
      "source": [
        "以下函数使用上述结果将强度 $X_{ij}\\in [0,1]$ 的特征转换为延迟编码响应 $L_{ij}$。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J06UgGHKTkea"
      },
      "outputs": [],
      "source": [
        "def convert_to_time(data, tau=5, threshold=0.01):\n",
        "  spike_time = tau * torch.log(data / (data - threshold))\n",
        "  return spike_time"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "voBg5kujkGFQ"
      },
      "source": [
        "现在，使用上述函数可视化输入特征强度与其相应尖峰时间之间的关系。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "52PwqfpKkK-I"
      },
      "outputs": [],
      "source": [
        "raw_input = torch.arange(0, 5, 0.05) # tensor from 0 to 5\n",
        "spike_times = convert_to_time(raw_input)\n",
        "\n",
        "plt.plot(raw_input, spike_times)\n",
        "plt.xlabel('Input Value')\n",
        "plt.ylabel('Spike Time (s)')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P972FBhmluv3"
      },
      "source": [
        "值越小，尖峰出现越晚，具有指数依赖性。\n",
        "\n",
        "向量`spike_times`包含触发尖峰的时间，而不是包含尖峰本身（1 和 0）的稀疏张量。\n",
        "\n",
        "运行 SNN 模拟时，我们需要 1/0 来表示所有尖峰。\n",
        "\n",
        "整个过程可以使用`spikegen.latency`自动化，我们在`data_it`中传递来自 MNIST 数据集的小批量："
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m835u23QobY-",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "spike_data = spikegen.latency(data_it, num_steps=100, tau=5, threshold=0.01)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AKDPjTvKobY_",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "一些论点包括：\n",
        "\n",
        "* `tau`: 电路的 RC 时间常数。 默认情况下，输入特性被视为注入 RC 电路的恒定电流。 较高的`tau`会导致产生尖峰的速度变慢。\n",
        "* `threshold`：膜电位产生尖峰阈值。低于该阈值的输入值没有闭式解，因为输入电流不足以驱动膜达到阈值。所有低于阈值的值都会被剪切并分配到最后一个时间步骤。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VGH7b49SobY_",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "#### 2.3.1 栅格图"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kypMtfF7obY_",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "fig = plt.figure(facecolor=\"w\", figsize=(10, 5))\n",
        "ax = fig.add_subplot(111)\n",
        "splt.raster(spike_data[:, 0].view(num_steps, -1), ax, s=25, c=\"black\")\n",
        "\n",
        "plt.title(\"Input Layer\")\n",
        "plt.xlabel(\"Time step\")\n",
        "plt.ylabel(\"Neuron Number\")\n",
        "plt.show()\n",
        "\n",
        "# optional save\n",
        "# fig.savefig('destination_path.png', format='png', dpi=300)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hm1--DHYobZA",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "要理解栅格图，请注意高强度特征先产生尖峰，而低强度特征最后尖峰：\n",
        "\n",
        "<center>\n",
        "<img src='https://github.com/jeshraghian/snntorch/blob/master/docs/_static/img/examples/tutorial1/1_2_5_latencyraster.png?raw=true' width=\"800\">\n",
        "</center>\n",
        "\n",
        "对数代码加上缺乏不同的输入值（即缺乏中间色调/灰度特征）导致图中两个区域出现明显的聚类。\n",
        "\n",
        "亮像素在运行开始时产生尖峰，而暗像素则在运行结束时产生尖峰。\n",
        "\n",
        "我们可以增加 `tau` 来减慢尖峰时间，或者通过设置可选参数 `linear=True` 来线性化尖峰时间。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZX8azDNWobZA",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "spike_data = spikegen.latency(data_it, num_steps=100, tau=5, threshold=0.01, linear=True)\n",
        "\n",
        "fig = plt.figure(facecolor=\"w\", figsize=(10, 5))\n",
        "ax = fig.add_subplot(111)\n",
        "splt.raster(spike_data[:, 0].view(num_steps, -1), ax, s=25, c=\"black\")\n",
        "plt.title(\"Input Layer\")\n",
        "plt.xlabel(\"Time step\")\n",
        "plt.ylabel(\"Neuron Number\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pZuk6g3NobZB",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "现在，产生尖峰的时间的分布更加均匀。这是通过将对数方程线性化来实现的，具体规则如下。与 RC 模型不同，该模型没有物理基础。它只是更简单而已。\n",
        "\n",
        "<center>\n",
        "<img src='https://github.com/jeshraghian/snntorch/blob/master/docs/_static/img/examples/tutorial1/1_2_6_latencylinear.png?raw=true' width=\"600\">\n",
        "</center>\n",
        "\n",
        "\n",
        "但请注意，所有尖峰都发生在前约 5 个时间步内，而模拟范围是 100 个时间步。\n",
        "这表明我们有很多多余的时间步没有做任何事情。要解决这个问题，可以增加 `tau` 来减慢时间常数，或者设置可选参数 `normalize=True` 来跨越整个 `num_steps` 范围。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RLgntdwSobZB",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "spike_data = spikegen.latency(data_it, num_steps=100, tau=5, threshold=0.01,\n",
        "                              normalize=True, linear=True)\n",
        "\n",
        "fig = plt.figure(facecolor=\"w\", figsize=(10, 5))\n",
        "ax = fig.add_subplot(111)\n",
        "splt.raster(spike_data[:, 0].view(num_steps, -1), ax, s=25, c=\"black\")\n",
        "\n",
        "plt.title(\"Input Layer\")\n",
        "plt.xlabel(\"Time step\")\n",
        "plt.ylabel(\"Neuron Number\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1EFIqaylobZC",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "与速率编码相比，延迟编码的一大优势在于稀疏性。如果神经元被限制在感兴趣的时间过程中只产生一次尖峰，那么这将促进低功耗运行。\n",
        "\n",
        "在上图所示的场景中，大部分尖峰发生在最后一个时间步长，此时输入特征低于阈值。从某种意义上说，MNIST 样本的深色背景并不包含有用的信息。\n",
        "\n",
        "我们可以通过设置 `clip=True` 来去除这些冗余特征。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uowgb4FPobZC",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "spike_data = spikegen.latency(data_it, num_steps=100, tau=5, threshold=0.01,\n",
        "                              clip=True, normalize=True, linear=True)\n",
        "\n",
        "fig = plt.figure(facecolor=\"w\", figsize=(10, 5))\n",
        "ax = fig.add_subplot(111)\n",
        "splt.raster(spike_data[:, 0].view(num_steps, -1), ax, s=25, c=\"black\")\n",
        "\n",
        "plt.title(\"Input Layer\")\n",
        "plt.xlabel(\"Time step\")\n",
        "plt.ylabel(\"Neuron Number\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W7gN02QOobZC",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "这样看起来就好多了"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XG9erdfxobZD",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "#### 2.3.2 动画化\n",
        "我们将运行与之前完全相同的代码块来创建动画。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BjLC1Pl_obZD",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "spike_data_sample = spike_data[:, 0, 0]\n",
        "print(spike_data_sample.size())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uwVwMVpzobZD",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "fig, ax = plt.subplots()\n",
        "anim = splt.animator(spike_data_sample, fig, ax)\n",
        "\n",
        "HTML(anim.to_html5_video())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FONW5DIkobZE",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "该动画显然以视频形式更难看清，但敏锐的眼睛将能够瞥见大多数尖峰发生的初始帧。\n",
        "\n",
        "索引到相应的目标值以检查其值。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VgNLaB90obZD",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "# Save output: .gif, .mp4 etc.\n",
        "# anim.save(\"mnist_latency.gif\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wrqfPu43obZE",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "print(targets_it[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sl93G7LwnG67"
      },
      "source": [
        "这就是`spikegen.latency`函数。 更多信息[可以在此处的文档中找到](https://snntorch.readthedocs.io/en/latest/snntorch.spikegen.html)。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uxe0msNpmpcN"
      },
      "source": [
        "### 2.4 Delta 调制 / 增量调制\n",
        "\n",
        "有理论认为视网膜具有适应性：只有当有新的东西需要处理时，它才会处理信息。  如果您的视野没有变化，那么您的感光细胞就不太容易放电。\n",
        "\n",
        "也就是说：**生物学是事件驱动的**。  神经元在变化中茁壮成长。\n",
        "\n",
        "举一个有趣的例子，一些研究人员毕生致力于设计受视网膜启发的图像传感器，例如 [动态视觉传感器](https://ieeexplore.ieee.org/abstract/document/7128412/)。  尽管 [所附链接来自十多年前，但该视频中的工作](https://www.youtube.com/watch?v=6eOM15U_t1M&ab_channel=TobiDelbruck) 是超前的。\n",
        "\n",
        "增量调制基于事件驱动的尖峰。 `snntorch.delta` 函数接受时间序列张量作为输入。  它获取所有时间步骤中每个后续特征之间的差异。  默认情况下，如果差异均为 *正* 且 *大于阈值 $V_{thr}$*，则会生成尖峰：\n",
        "\n",
        "<center>\n",
        "<img src='https://github.com/jeshraghian/snntorch/blob/master/docs/_static/img/examples/tutorial1/1_2_7_delta.png?raw=true' width=\"600\">\n",
        "</center>\n",
        "\n",
        "为了说明这一点，我们首先举一个人为例子，在其中创建我们自己的输入张量。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0AOr1kN-r4n-"
      },
      "outputs": [],
      "source": [
        "# 使用一些虚假的时间序列数据创建一个张量\n",
        "data = torch.Tensor([0, 1, 0, 2, 8, -20, 20, -5, 0, 1, 0])\n",
        "\n",
        "# Plot the tensor\n",
        "plt.plot(data)\n",
        "\n",
        "plt.title(\"Some fake time-series data\")\n",
        "plt.xlabel(\"Time step\")\n",
        "plt.ylabel(\"Voltage (mV)\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ih_UJ526tJPo"
      },
      "source": [
        "将上述张量传递到 `spikegen.delta` 函数中，并任意选择 `threshold=4`："
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WSNI1zGdtHac"
      },
      "outputs": [],
      "source": [
        "# 转换数据\n",
        "spike_data = spikegen.delta(data, threshold=4)\n",
        "\n",
        "# 生成 fig, ax\n",
        "fig = plt.figure(facecolor=\"w\", figsize=(8, 1))\n",
        "ax = fig.add_subplot(111)\n",
        "\n",
        "# 增量转换数据的栅格图\n",
        "splt.raster(spike_data, ax, c=\"black\")\n",
        "\n",
        "plt.title(\"Input Neuron\")\n",
        "plt.xlabel(\"Time step\")\n",
        "plt.yticks([])\n",
        "plt.xlim(0, len(data))\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dlmCwN40uPLq"
      },
      "source": [
        "在三个时间步中，$data [T]$ 和 $data [T+1]$ 之间的差值大于或等于 $V_{thr}=4$。  这意味着存在三个 “尖峰”。\n",
        "\n",
        "上面没有捕捉到 -20 的大幅下降。 如果负波动对您的数据很重要，您可以启用可选参数 `off_spike=True`。\n",
        "\n",
        "注： -20是上面data的输入数据。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WMrUGhRnuN8e"
      },
      "outputs": [],
      "source": [
        "# Convert data\n",
        "spike_data = spikegen.delta(data, threshold=4, off_spike=True)\n",
        "\n",
        "# Create fig, ax\n",
        "fig = plt.figure(facecolor=\"w\", figsize=(8, 1))\n",
        "ax = fig.add_subplot(111)\n",
        "\n",
        "# Raster plot of delta converted data\n",
        "splt.raster(spike_data, ax, c=\"black\")\n",
        "\n",
        "plt.title(\"Input Neuron\")\n",
        "plt.xlabel(\"Time step\")\n",
        "plt.yticks([])\n",
        "plt.xlim(0, len(data))\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S_5FajsDvnEw"
      },
      "source": [
        "我们已经生成了额外的峰值，但这实际上并不是完整的图片！\n",
        "\n",
        " 打印张量将显示 “非尖峰” 的存在，其值为 “-1”。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9deHKE2zxGA5"
      },
      "outputs": [],
      "source": [
        "print(spike_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Nz32V0fxm2d"
      },
      "source": [
        "虽然`spikegen.delta`仅在假数据样本上进行了演示，但其真正用途是通过仅针对足够大的变化/事件生成尖峰来压缩时间序列数据。\n",
        "\n",
        "这包含了三个主要的尖峰转换函数！ 这三种转换技术中的每一种还有一些本教程中未详细介绍的附加功能。 特别是，我们只研究了对输入数据进行编码； 我们还没有考虑如何对目标进行编码，以及何时需要编码。 我们建议[参考文档进行更深入的研究](https://snntorch.readthedocs.io/en/latest/snntorch.spikegen.html)。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mxrGoLIjobZE",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "## 3. 尖峰生成器（可选）\n",
        "\n",
        "现在，如果我们实际上没有任何数据可以开始怎么办？\n",
        "假设我们只想从头开始随机生成一个尖峰序列。代替`spikegen.rate`是一个嵌套函数 `rate_conv`，它实际上执行尖峰转换步骤。\n",
        "\n",
        "我们所要做的就是初始化一个随机生成的 `torchTensor` 并传入。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-Q_7uj0vobZE",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "# Create a random spike train\n",
        "spike_prob = torch.rand((num_steps, 28, 28), dtype=dtype) * 0.5\n",
        "spike_rand = spikegen.rate_conv(spike_prob)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KOy-NZ5YobZF",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "### 3.1 动画"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yCIwKN0WobZF",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "fig, ax = plt.subplots()\n",
        "anim = splt.animator(spike_rand, fig, ax)\n",
        "\n",
        "HTML(anim.to_html5_video())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kx-VKWxFobZF",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "# Save output: .gif, .mp4 etc.\n",
        "# anim.save(\"random_spikes.gif\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C_IH912xobZF",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "### 3.2 栅格图"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F6QgcKCrobZF",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "fig = plt.figure(facecolor=\"w\", figsize=(10, 5))\n",
        "ax = fig.add_subplot(111)\n",
        "splt.raster(spike_rand[:, 0].view(num_steps, -1), ax, s=25, c=\"black\")\n",
        "\n",
        "plt.title(\"Input Layer\")\n",
        "plt.xlabel(\"Time step\")\n",
        "plt.ylabel(\"Neuron Number\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QwEXpWkRy8_N"
      },
      "source": [
        "# 总结"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N-SsITWKobZF",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "\n",
        "这就是尖峰转换和生成。\n",
        "\n",
        "这种方法可以推广到图像之外的单维和多维张量。\n",
        "\n",
        "作为参考，[`spikegen` 的文档可以在这里找到](https://snntorch.readthedocs.io/en/latest/snntorch.spikegen.html) 和 [`spikeplot`，在这里](https:// snntorch.readthedocs.io/en/latest/snntorch.spikeplot.html)\n",
        "\n",
        "[在下一个教程中](https://snntorch.readthedocs.io/en/latest/tutorials/index.html)，您将学习尖峰神经元的基础知识以及如何使用它们。\n",
        "\n",
        "如果您喜欢这个项目，请考虑为 GitHub 上的存储库加注星标，因为这是支持它的最简单、最好的方式。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yqHiiAVoeE7I"
      },
      "source": [
        "# Additional Resources\n",
        "\n",
        "* [Check out the snnTorch GitHub project here.](https://github.com/jeshraghian/snntorch)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "9QXsrr6Mp5e_",
        "1EWDw3bip8Ie",
        "vFM8UV9CreIX",
        "xXkTAJ9ws1Y6",
        "OgkWg605tE1y",
        "OBt0WDzyujnk",
        "xC96eesMqYo-",
        "mszPTrYOluym",
        "VTHK-wAWV57B"
      ],
      "name": "Copy of quantAwareTrain.ipynb",
      "provenance": []
    },
    "interpreter": {
      "hash": "579503e60735c0b0ad61cf404d04af89041cf694c55fa4cc17d05f5d9b483dbc"
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
