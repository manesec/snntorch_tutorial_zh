{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "47d5313e-c29d-4581-a9c7-a45122337069",
      "metadata": {
        "id": "47d5313e-c29d-4581-a9c7-a45122337069"
      },
      "source": [
        "[<img src='https://github.com/jeshraghian/snntorch/blob/master/docs/_static/img/snntorch_alpha_w.png?raw=true' width=\"300\">](https://github.com/jeshraghian/snntorch/)\n",
        "[<img src='https://github.com/neuromorphs/tonic/blob/develop/docs/_static/tonic-logo-white.png?raw=true' width=\"200\">](https://github.com/neuromorphs/tonic/)\n",
        "\n",
        "\n",
        "# Neuromorphic Datasets with Tonic + snnTorch\n",
        "## Tutorial 7\n",
        "### By Gregor Lenz (lenzgregor.com) and Jason K. Eshraghian (www.ncg.ucsc.edu)\n",
        "### 偏白话文翻译： manesec\n",
        "\n",
        "<a href=\"https://colab.research.google.com/github/jeshraghian/snntorch/blob/master/examples/examples/tutorial_7_neuromorphic_datasets.ipynb\">\n",
        "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
        "</a>\n",
        "\n",
        "[<img src='https://github.com/jeshraghian/snntorch/blob/master/docs/_static/img/GitHub-Mark-Light-120px-plus.png?raw=true' width=\"28\">](https://github.com/jeshraghian/snntorch/) [<img src='https://github.com/jeshraghian/snntorch/blob/master/docs/_static/img/GitHub_Logo_White.png?raw=true' width=\"80\">](https://github.com/jeshraghian/snntorch/)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "oll2NNFeG1NG",
      "metadata": {
        "id": "oll2NNFeG1NG"
      },
      "source": [
        "snnTorch 教程系列基于以下论文。如果您发现这些资源或代码对您有帮助，请考虑引用以下来源：\n",
        "\n",
        "> <cite> [Jason K. Eshraghian, Max Ward, Emre Neftci, Xinxin Wang, Gregor Lenz, Girish Dwivedi, Mohammed Bennamoun, Doo Seok Jeong, and Wei D. Lu. \"Training Spiking Neural Networks Using Lessons From Deep Learning\". arXiv preprint arXiv:2109.12894, September 2021.](https://arxiv.org/abs/2109.12894) </cite>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ClgsZMOfBVby",
      "metadata": {
        "id": "ClgsZMOfBVby"
      },
      "source": [
        "# 简介\n",
        "在本教程中，您将\n",
        "* 学习如何使用 [Tonic](https://github.com/neuromorphs/tonic) 加载神经形态数据集\n",
        "* 利用缓存加快数据加载速度\n",
        "* 使用 [Neuromorphic-MNIST](https://tonic.readthedocs.io/en/latest/datasets.html#n-mnist) 数据集训练 CSNN\n",
        "\n",
        "如果在 Google Colab 中运行：\n",
        "* 您可以通过检查 `Runtime` > `Change runtime type` > `Hardware accelerator： GPU`\n",
        "* 接下来，点击下面的单元格并按`Shift+Enter`键，安装 snnTorch 和 Tonic 的最新 PyPi 发行版。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "hDnIEHOKB8LD",
      "metadata": {
        "id": "hDnIEHOKB8LD"
      },
      "outputs": [],
      "source": [
        "!pip install tonic --quiet\n",
        "!pip install snntorch --quiet"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e93694d9-0f0a-46a0-b17f-c04ac9b73a63",
      "metadata": {
        "id": "e93694d9-0f0a-46a0-b17f-c04ac9b73a63"
      },
      "source": [
        "# 1. 使用 Tonic 加载神经形态数据集\n",
        "得益于 [Tonic](https://github.com/neuromorphs/tonic)，从神经形态传感器加载数据集变得非常简单，它的工作原理与 PyTorch 视觉非常相似。\n",
        "\n",
        "让我们首先加载 MNIST 数据集的神经形态版本，称为 [N-MNIST](https://tonic.readthedocs.io/en/latest/reference/datasets.html#n-mnist)。 我们可以查看一些原始事件来了解我们正在处理的内容。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7d286ef9-5fe6-4578-a686-91559a1f81d2",
      "metadata": {
        "id": "7d286ef9-5fe6-4578-a686-91559a1f81d2"
      },
      "outputs": [],
      "source": [
        "import tonic\n",
        "\n",
        "dataset = tonic.datasets.NMNIST(save_to='./data', train=True)\n",
        "events, target = dataset[0]\n",
        "print(events)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "IbnLy107Oo3a",
      "metadata": {
        "id": "IbnLy107Oo3a"
      },
      "source": [
        "每行对应一个事件，由四个参数组成：（*x 坐标、y 坐标、时间戳、极性*）。\n",
        "\n",
        "* x 和 y 坐标对应于 $34 \\times 34$ 网格中的地址。\n",
        "\n",
        "* 事件的时间戳以微秒为单位记录。\n",
        "\n",
        "* 极性是指是否发生正尖峰（+1）或离尖峰（-1）； 即，亮度增加或亮度降低。\n",
        "\n",
        "如果我们将这些事件随时间推移累积起来，并绘制成图像，看起来就像这样："
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e6d6a0b0-2a73-4dbe-9576-d06c251f0fa4",
      "metadata": {
        "id": "e6d6a0b0-2a73-4dbe-9576-d06c251f0fa4"
      },
      "outputs": [],
      "source": [
        "tonic.utils.plot_event_grid(events)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f6bcc031-d11a-4471-b3aa-335eec76d7ad",
      "metadata": {
        "id": "f6bcc031-d11a-4471-b3aa-335eec76d7ad"
      },
      "source": [
        "## 1.1 转换\n",
        "\n",
        "然而，神经网络不能把事件列表作为输入。原始数据必须转换为合适的表示形式，例如张量。 在将数据输入网络之前，我们可以选择一组应用于数据的转换。 举个例子，神经形态相机传感器的时间分辨率为微秒，当转换为密集表示时，最终会成为一个非常大的张量。 这就是为什么我们使用 [ToFrame 转换](https://tonic.readthedocs.io/en/latest/reference/transformations.html#frames) 将事件分成较少数量的帧，这会降低时间精度，但也允许我们以密集格式使用它。\n",
        "\n",
        "* `time_window=1000` 将事件集成到 1000 $~\\mu$ s 中\n",
        "\n",
        "* 去噪消除独立的，一次性事件。 如果在 `filter_time` 微秒内 1 像素的邻域内没有发生任何事件，则该事件将被过滤。 较小的 `filter_time` 将过滤更多事件。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "30f249be-8a65-4c1c-a21c-d561e904b4bf",
      "metadata": {
        "id": "30f249be-8a65-4c1c-a21c-d561e904b4bf"
      },
      "outputs": [],
      "source": [
        "import tonic.transforms as transforms\n",
        "\n",
        "sensor_size = tonic.datasets.NMNIST.sensor_size\n",
        "\n",
        "# Denoise removes isolated, one-off events\n",
        "# time_window\n",
        "frame_transform = transforms.Compose([transforms.Denoise(filter_time=10000),\n",
        "                                      transforms.ToFrame(sensor_size=sensor_size,\n",
        "                                                         time_window=1000)\n",
        "                                     ])\n",
        "\n",
        "trainset = tonic.datasets.NMNIST(save_to='./data', transform=frame_transform, train=True)\n",
        "testset = tonic.datasets.NMNIST(save_to='./data', transform=frame_transform, train=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3a6bf2a2-ff9f-4cdc-8cb3-02a1a9d71a11",
      "metadata": {
        "id": "3a6bf2a2-ff9f-4cdc-8cb3-02a1a9d71a11"
      },
      "outputs": [],
      "source": [
        "def load_sample_simple():\n",
        "    for i in range(100):\n",
        "        events, target = trainset[i]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1a9d3b28-b303-4a17-be78-b9918911a7cd",
      "metadata": {
        "id": "1a9d3b28-b303-4a17-be78-b9918911a7cd"
      },
      "outputs": [],
      "source": [
        "%timeit -o load_sample_simple()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3831428d-0511-4fde-84d9-11d08fa45df7",
      "metadata": {
        "id": "3831428d-0511-4fde-84d9-11d08fa45df7"
      },
      "source": [
        "## 1.2 快速数据加载\n",
        "\n",
        "原始数据的存储格式读取速度较慢。为了加快数据加载速度，我们可以使用磁盘缓存和批处理。这意味着，一旦文件从原始数据集加载，它们就会被写入磁盘。\n",
        "\n",
        "由于事件记录有不同的长度，我们将提供一个整理函数 `tonic.collation.PadTensors()` 来填充较短的记录，以确保批次中的所有样本具有相同的尺寸。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5b35c7cd-d292-47cd-9203-7f31aa7f7207",
      "metadata": {
        "id": "5b35c7cd-d292-47cd-9203-7f31aa7f7207"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import DataLoader\n",
        "from tonic import DiskCachedDataset\n",
        "\n",
        "cached_trainset = DiskCachedDataset(trainset, cache_path='./cache/nmnist/train')\n",
        "cached_dataloader = DataLoader(cached_trainset)\n",
        "\n",
        "batch_size = 128\n",
        "trainloader = DataLoader(cached_trainset, batch_size=batch_size, collate_fn=tonic.collation.PadTensors())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "14b9af4f-141e-4301-8451-445957ec8707",
      "metadata": {
        "id": "14b9af4f-141e-4301-8451-445957ec8707"
      },
      "outputs": [],
      "source": [
        "def load_sample_batched():\n",
        "    events, target = next(iter(cached_dataloader))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3dc4b27a-63ac-4edc-94e9-589d548c4769",
      "metadata": {
        "id": "3dc4b27a-63ac-4edc-94e9-589d548c4769"
      },
      "outputs": [],
      "source": [
        "%timeit -o -r 10 load_sample_batched()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a82a7afd-c011-4cd6-ba04-1e7cd438bc1f",
      "metadata": {
        "id": "a82a7afd-c011-4cd6-ba04-1e7cd438bc1f"
      },
      "source": [
        "通过使用磁盘缓存和支持多线程和批处理的 PyTorch 数据加载器，大大缩短了加载时间。\n",
        "\n",
        "如果你有大量可用内存，可以尝试把通过缓存加载到主内存而不是磁盘上来进一步加快数据的加载速度：\n",
        "\n",
        "```\n",
        "from tonic import MemoryCachedDataset\n",
        "\n",
        "cached_trainset = MemoryCachedDataset(trainset)\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2ded1bd9-e2f1-479e-899c-c6c2652e6fc9",
      "metadata": {
        "id": "2ded1bd9-e2f1-479e-899c-c6c2652e6fc9"
      },
      "source": [
        "# 2. 利用从事件中创建的帧来训练我们的网络"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9be82d75-69ef-4c1b-ad85-4eca84c73ccf",
      "metadata": {
        "id": "9be82d75-69ef-4c1b-ad85-4eca84c73ccf"
      },
      "source": [
        "现在，让我们在 N-MNIST 分类任务中实际训练一个网络。我们首先要定义缓存封装器和数据加载器。同时，我们还要对训练数据进行一些增强。\n",
        "\n",
        "我们从缓存数据集获得的样本是帧，因此我们可以利用 PyTorch Vision 来应用我们想要的任何随机变换。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ace6cd0b-7b56-4422-b3bd-23bac65db9bd",
      "metadata": {
        "id": "ace6cd0b-7b56-4422-b3bd-23bac65db9bd"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "\n",
        "transform = tonic.transforms.Compose([torch.from_numpy,\n",
        "                                      torchvision.transforms.RandomRotation([-10,10])])\n",
        "\n",
        "cached_trainset = DiskCachedDataset(trainset, transform=transform, cache_path='./cache/nmnist/train')\n",
        "\n",
        "# no augmentations for the testset\n",
        "cached_testset = DiskCachedDataset(testset, cache_path='./cache/nmnist/test')\n",
        "\n",
        "batch_size = 128\n",
        "trainloader = DataLoader(cached_trainset, batch_size=batch_size, collate_fn=tonic.collation.PadTensors(batch_first=False), shuffle=True)\n",
        "testloader = DataLoader(cached_testset, batch_size=batch_size, collate_fn=tonic.collation.PadTensors(batch_first=False))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "528fe384-a365-4b53-bbfc-ed4dd261d222",
      "metadata": {
        "id": "528fe384-a365-4b53-bbfc-ed4dd261d222"
      },
      "source": [
        "现在小批量具有维度（时间步长、批量大小、通道、高度、宽度）。  时间步数将使用小批量中最长记录的时间间隔，所有其他样本将用零填充以匹配它。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c9e37337-ad4a-43d5-b429-81a18de5148e",
      "metadata": {
        "id": "c9e37337-ad4a-43d5-b429-81a18de5148e"
      },
      "outputs": [],
      "source": [
        "event_tensor, target = next(iter(trainloader))\n",
        "print(event_tensor.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "61ae5d4b-2bb3-4191-9f96-04b3c6ba4c41",
      "metadata": {
        "id": "61ae5d4b-2bb3-4191-9f96-04b3c6ba4c41"
      },
      "source": [
        "## 2.1 定义我们的网络\n",
        "\n",
        "我们将使用 snnTorch + PyTorch 构建一个 CSNN，就像之前的教程一样。要使用的卷积网络架构是：12C5-MP2-32C5-MP2-800FC10\n",
        "\n",
        "- `12C5` 是一个  5 $\\times$ 5 的卷积核，有 12 个滤波器\n",
        "- `MP2` 是一个 2 $\\times$ 2 最大池化函数\n",
        "- `800FC10` 是一个全连接层，将 800 个神经元映射到 10 个输出端\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "HpKDIkRKUIAB",
      "metadata": {
        "id": "HpKDIkRKUIAB"
      },
      "outputs": [],
      "source": [
        "import snntorch as snn\n",
        "from snntorch import surrogate\n",
        "from snntorch import functional as SF\n",
        "from snntorch import spikeplot as splt\n",
        "from snntorch import utils\n",
        "import torch.nn as nn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "107cb645-0227-4290-9e1b-25d6ae7eac87",
      "metadata": {
        "id": "107cb645-0227-4290-9e1b-25d6ae7eac87"
      },
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
        "\n",
        "# neuron and simulation parameters\n",
        "spike_grad = surrogate.atan()\n",
        "beta = 0.5\n",
        "\n",
        "#  Initialize Network\n",
        "net = nn.Sequential(nn.Conv2d(2, 12, 5),\n",
        "                    snn.Leaky(beta=beta, spike_grad=spike_grad, init_hidden=True),\n",
        "                    nn.MaxPool2d(2),\n",
        "                    nn.Conv2d(12, 32, 5),\n",
        "                    snn.Leaky(beta=beta, spike_grad=spike_grad, init_hidden=True),\n",
        "                    nn.MaxPool2d(2),\n",
        "                    nn.Flatten(),\n",
        "                    nn.Linear(32*5*5, 10),\n",
        "                    snn.Leaky(beta=beta, spike_grad=spike_grad, init_hidden=True, output=True)\n",
        "                    ).to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "zPFvlqOGi_uW",
      "metadata": {
        "id": "zPFvlqOGi_uW"
      },
      "outputs": [],
      "source": [
        "# this time, we won't return membrane as we don't need it\n",
        "\n",
        "def forward_pass(net, data):\n",
        "  spk_rec = []\n",
        "  utils.reset(net)  # resets hidden states for all LIF neurons in net\n",
        "\n",
        "  for step in range(data.size(0)):  # data.size(0) = number of time steps\n",
        "      spk_out, mem_out = net(data[step])\n",
        "      spk_rec.append(spk_out)\n",
        "\n",
        "  return torch.stack(spk_rec)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "23569dfc-e4a7-490f-8a68-c9ade5e03028",
      "metadata": {
        "id": "23569dfc-e4a7-490f-8a68-c9ade5e03028"
      },
      "source": [
        "## 2.2 训练\n",
        "\n",
        "在上一教程中，交叉熵损失被应用于总尖峰计数，以最大化来自正确类别的尖峰数。\n",
        "\n",
        "`snn.functional` 模块的另一个选项是指定来自正确和不正确类别的目标尖峰数。下面的方法使用了 \"均方误差尖峰计数损失\"（*Mean Square Error Spike Count Loss*），其目标是在 80% 的时间内从正确类中激发尖峰，在 20% 的时间内从错误类中激发尖峰。鼓励不正确的神经元不产生尖峰可以避免神经元死亡。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "VocYbtD7Vwp7",
      "metadata": {
        "id": "VocYbtD7Vwp7"
      },
      "outputs": [],
      "source": [
        "optimizer = torch.optim.Adam(net.parameters(), lr=2e-2, betas=(0.9, 0.999))\n",
        "loss_fn = SF.mse_count_loss(correct_rate=0.8, incorrect_rate=0.2)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7xkKLsqnmzcw",
      "metadata": {
        "id": "7xkKLsqnmzcw"
      },
      "source": [
        "训练神经形态数据的成本很高，因为它需要依次迭代许多时间步（N-MNIST 数据集约有 300 个时间步）。下面的模拟将耗费一些时间，因此我们将坚持训练 50 次迭代（大约是一个完整训练过程的 1/10）。如果时间充裕，可以随意更改 `num_iters`。由于在每次迭代时都会打印结果，因此结果会比较吵，不过也需要等待一段时间才能开始看到任何改进。\n",
        "\n",
        "在自己的实验中，大约经过 20 次迭代后我们才看到任何改进，而在 50 次迭代后，我们成功地破解了 ~60% 的准确率。\n",
        "\n",
        "> 警告：下面的模拟将耗费一段时间。去给自己冲杯咖啡，或者..... 十杯。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "R4GbPSdTUcUR",
      "metadata": {
        "id": "R4GbPSdTUcUR"
      },
      "outputs": [],
      "source": [
        "num_epochs = 1\n",
        "num_iters = 50\n",
        "\n",
        "loss_hist = []\n",
        "acc_hist = []\n",
        "\n",
        "# training loop\n",
        "for epoch in range(num_epochs):\n",
        "    for i, (data, targets) in enumerate(iter(trainloader)):\n",
        "        data = data.to(device)\n",
        "        targets = targets.to(device)\n",
        "\n",
        "        net.train()\n",
        "        spk_rec = forward_pass(net, data)\n",
        "        loss_val = loss_fn(spk_rec, targets)\n",
        "\n",
        "        # Gradient calculation + weight update\n",
        "        optimizer.zero_grad()\n",
        "        loss_val.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # Store loss history for future plotting\n",
        "        loss_hist.append(loss_val.item())\n",
        "\n",
        "        print(f\"Epoch {epoch}, Iteration {i} \\nTrain Loss: {loss_val.item():.2f}\")\n",
        "\n",
        "        acc = SF.accuracy_rate(spk_rec, targets)\n",
        "        acc_hist.append(acc)\n",
        "        print(f\"Accuracy: {acc * 100:.2f}%\\n\")\n",
        "\n",
        "        # This will end training after 50 iterations by default\n",
        "        if i == num_iters:\n",
        "          break"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "YVjUzNcX0wld",
      "metadata": {
        "id": "YVjUzNcX0wld"
      },
      "source": [
        "# 3. 结果\n",
        "## 3.1 绘图测试精度"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "yp2aTX2_1zFG",
      "metadata": {
        "id": "yp2aTX2_1zFG"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Plot Loss\n",
        "fig = plt.figure(facecolor=\"w\")\n",
        "plt.plot(acc_hist)\n",
        "plt.title(\"Train Set Accuracy\")\n",
        "plt.xlabel(\"Iteration\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1gb1wCQb2bMd",
      "metadata": {
        "id": "1gb1wCQb2bMd"
      },
      "source": [
        "## 3.2 尖峰计数器\n",
        "\n",
        "对一批数据进行前向传递，以获得尖峰记录。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "qLAfvj9D2AYd",
      "metadata": {
        "id": "qLAfvj9D2AYd"
      },
      "outputs": [],
      "source": [
        "spk_rec = forward_pass(net, data)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "VQnj40YC2hUV",
      "metadata": {
        "id": "VQnj40YC2hUV"
      },
      "source": [
        "更改 `idx` 可以对迷你批中的各种样本进行索引。使用 `splt.spike_count` 来探索几个不同样本的尖峰行为。生成以下动画需要一些时间。\n",
        "\n",
        "> 注意：如果您在本地桌面上运行笔记本，请取消下面一行的注释并修改 ffmpeg.exe 的路径\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "oTKhuyk22M57",
      "metadata": {
        "id": "oTKhuyk22M57"
      },
      "outputs": [],
      "source": [
        "from IPython.display import HTML\n",
        "\n",
        "idx = 0\n",
        "\n",
        "fig, ax = plt.subplots(facecolor='w', figsize=(12, 7))\n",
        "labels=['0', '1', '2', '3', '4', '5', '6', '7', '8','9']\n",
        "print(f\"The target label is: {targets[idx]}\")\n",
        "\n",
        "plt.rcParams['animation.ffmpeg_path'] = 'D:\\\\GoodApp\\\\ffmpeg\\\\bin\\\\ffmpeg.exe'\n",
        "\n",
        "#  Plot spike count histogram\n",
        "anim = splt.spike_count(spk_rec[:, idx].detach().cpu(), fig, ax, labels=labels,\n",
        "                        animate=True, interpolate=1)\n",
        "\n",
        "HTML(anim.to_html5_video())\n",
        "# anim.save(\"spike_bar.mp4\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "-iSGTq0Q3Lcm",
      "metadata": {
        "id": "-iSGTq0Q3Lcm"
      },
      "source": [
        "# 结论\n",
        "如果你做到了这一步，那么恭喜你--你拥有僧侣般的耐心。你现在应该也了解了如何使用 Tonic 加载神经形态数据集，然后使用 snnTorch 训练网络。\n",
        "\n",
        "深度挖掘系列教程到此结束。\n",
        "\n",
        "请访问 [高级教程](https://snntorch.readthedocs.io/en/latest/tutorials/index.html) 了解更多高级技术，例如在 SNN 中引入长期时间动态、种群编码或在智能处理单元上加速。\n",
        "\n",
        "如果您喜欢这个项目，请考虑在 GitHub 上的 repo ⭐ 星级，因为这是最简单、最好的支持方式。\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "h-K_DUnsMKnv",
      "metadata": {
        "id": "h-K_DUnsMKnv"
      },
      "source": [
        "# Additional Resources\n",
        "* [Check out the snnTorch GitHub project here.](https://github.com/jeshraghian/snntorch)\n",
        "* [The Tonic GitHub project can be found here.](https://github.com/neuromorphs/tonic)\n",
        "* The N-MNIST Dataset was originally published in the following paper: [Orchard, G.; Cohen, G.; Jayawant, A.; and Thakor, N.  “Converting Static Image Datasets to Spiking Neuromorphic Datasets Using Saccades\", Frontiers in Neuroscience, vol.9, no.437, Oct. 2015.](https://www.frontiersin.org/articles/10.3389/fnins.2015.00437/full)\n",
        "* For further information about how N-MNIST was created, please refer to [Garrick Orchard's website here.](https://www.garrickorchard.com/datasets/n-mnist)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Copy of tutorial_5_neuromorphic_datasets.ipynb",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
